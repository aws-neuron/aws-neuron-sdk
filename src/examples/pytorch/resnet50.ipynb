{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet50 model for Inferentia\n",
    "\n",
    "\n",
    "## Introduction:\n",
    "\n",
    "In this tutorial we will compile and deploy Resnet-50 model for Inferentia. This Jupyter notebook should be run on an instance which is inf1.6xlarge or larger. The compile part of this tutorial requires inf1.6xlarge and not the inference itself. For simplicity we will run this tutorial on inf1.6xlarge but in real life scenario the compilation should be done on a compute instance and the deployment on inf1 instance to save costs. \n",
    "\n",
    "In this tutorial we provide three main sections:\n",
    "\n",
    "1. Compile the Resnet50 model and infer with batch size of 1\n",
    "\n",
    "2. Run the same compiled model on multiple cores\n",
    "\n",
    "3. Compile the Resnet50 model with batch size 5 and run it on multiple cores\n",
    "\n",
    "Before running the following verify this Jupyter notebook is running \"conda_aws_neuron_pytorch_p36\" kernel. You can select the Kernel from the \"Kernel -> Change Kernel\" option on the top of this Jupyter notebook page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies:\n",
    "This tutorial requires the following pip packages:\n",
    "\n",
    "- `torch-neuron`\n",
    "- `torchvision`\n",
    "- `neuron-cc[tensorflow]`\n",
    "\n",
    "These will be installed by default when configuring your environment using the Neuron PyTorch setup guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile model for Neuron\n",
    "\n",
    "The following step will compile the resnet50 model. This will take a few minutes. At the end of script execution, the compiled model is saved as `resnet50_neuron.pt` in local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import torch_neuron\n",
    "from torchvision import models\n",
    "import logging\n",
    "\n",
    "## Enable logging so we can see any important warnings\n",
    "logger = logging.getLogger('Neuron')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "image = torch.zeros([1, 3, 224, 224], dtype=torch.float32)\n",
    "\n",
    "## Load a pretrained ResNet50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "## Tell the model we are using it for evaluation (not training)\n",
    "model.eval()\n",
    "\n",
    "## Analyze the model - this will show operator support and operator count\n",
    "torch.neuron.analyze_model( model, example_inputs=[image] )\n",
    "\n",
    "## Now compile the model - with logging set to \"info\" we will see\n",
    "## what compiles for Neuron, and if there are any fallbacks\n",
    "## Note: The \"-O2\" setting is default in recent releases, but may be needed for DLAMI\n",
    "##       and older installed environments- model_neuron = torch.neuron.trace(model, example_inputs=[image], compiler_args=\"-O2\")\n",
    "model_neuron = torch.neuron.trace(model, example_inputs=[image])\n",
    "\n",
    "# The output of this step will have the percentage of operations compiled, example:\n",
    "#\n",
    "# INFO:Neuron:The neuron partitioner created 1 sub-graphs\n",
    "# INFO:Neuron:Neuron successfully compiled 1 sub-graphs, Total fused subgraphs = 1, Percent of model sub-graphs successfully compiled = 100.0%\n",
    "\n",
    "## Export to saved model\n",
    "model_neuron.save(\"resnet50_neuron.pt\")\n",
    "print(\"Compile Args, input tensor: {}, data type:'fp32', 'core': 1 \")\n",
    "print(\"Compile success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference on Single Core\n",
    "\n",
    "Initially we will just use one of the available neuron cores. Do not perform inference with a neuron traced model on a non neuron supported instance, results will not be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch_neuron\n",
    "import json\n",
    "import numpy as np\n",
    "from urllib import request\n",
    "from torchvision import models, transforms, datasets\n",
    "from time import time\n",
    "\n",
    "## Create an image directory containing a small kitten\n",
    "os.makedirs(\"./torch_neuron_test/images\", exist_ok=True)\n",
    "request.urlretrieve(\"https://raw.githubusercontent.com/awslabs/mxnet-model-server/master/docs/images/kitten_small.jpg\",\n",
    " \"./torch_neuron_test/images/kitten_small.jpg\")\n",
    "\n",
    "## Fetch labels to output the top classifications\n",
    "request.urlretrieve(\"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\",\"imagenet_class_index.json\")\n",
    "idx2label = []\n",
    "\n",
    "with open(\"imagenet_class_index.json\", \"r\") as read_file:\n",
    " class_idx = json.load(read_file)\n",
    " idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]\n",
    "\n",
    "## Import a sample image and normalize it into a tensor\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225])\n",
    "\n",
    "eval_dataset = datasets.ImageFolder(\n",
    "    os.path.dirname(\"./torch_neuron_test/\"),\n",
    "    transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    ")\n",
    "image, _ = eval_dataset[0]\n",
    "image = torch.tensor(image.numpy()[np.newaxis, ...])\n",
    "\n",
    "## Load model\n",
    "model_neuron = torch.jit.load( 'resnet50_neuron.pt' )\n",
    "\n",
    "## Since the first inference also load the model let's exclude it \n",
    "## from timing\n",
    "results = model_neuron( image )\n",
    "\n",
    "## Predict for 100 loops\n",
    "start = time()\n",
    "\n",
    "loops = 100\n",
    "for _ in range(loops):\n",
    "    results = model_neuron( image )\n",
    "elapsed_time = time() - start\n",
    "images_sec = loops / float(elapsed_time)\n",
    "\n",
    "# Get the top 5 results\n",
    "top5_idx = results[0].sort()[1][-5:]\n",
    "\n",
    "# Lookup and print the top 5 labels\n",
    "top5_labels = [idx2label[idx] for idx in top5_idx]\n",
    "\n",
    "# The output from above will look like:\n",
    "#\n",
    "# ['tiger', 'lynx', 'tiger_cat', 'Egyptian_cat', 'tabby']\n",
    "# Batch size: 1, Throughput: 267.0 images / second\n",
    "\n",
    "print(\"Top 5 labels:\\n {}\".format(top5_labels) )\n",
    "print(\"Batch size: 1, Throughput: {} images / second\".format(round(images_sec,0) ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference on parallel neuron cores\n",
    "\n",
    "To fully leverage the inferentia hardware we want to use all the cores.  On an inf1.xlarge or inf1.2xlarge we have four available cores, with 16 cores on inf1.6xlarge and 64 cores on inf1.24xlarge instances.   Here we use the futures library to create a simple class that runs four parallel inference threads\n",
    "\n",
    "Using all of the available cores is important for achieving maximum performance on Neuron hardware.  The implementation below uses an aggregated batch size.  \n",
    "\n",
    "* It loads the model into four cores\n",
    "* At input it accepts a batch four times the size of the compiled model\n",
    "* It splits the data across the four cores, and once all cores are done collates the output into a result tensor\n",
    "\n",
    "This is intended as a good starting implementation - but you may want to vary it depending on your application\n",
    "\n",
    "\n",
    "In the following we create a data parallel class which handles larger tensor batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "import torch\n",
    "import torch.neuron\n",
    "import os\n",
    "\n",
    "class NeuronSimpleDataParallel():\n",
    "\n",
    "    def __init__(self, model_file, num_neuron_cores, batch_size=1):\n",
    "        # Construct a list of models\n",
    "        self.num_neuron_cores = num_neuron_cores\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        class SimpleWrapper():\n",
    "\n",
    "            def __init__(self, model):\n",
    "                self.model = model\n",
    "\n",
    "            def eval(self):\n",
    "                self.model.eval()\n",
    "\n",
    "            def train(self):\n",
    "                self.model.train()\n",
    "\n",
    "            def __call__(self, *args):\n",
    "                results = self.model(*args)\n",
    "\n",
    "                # Make the output iterable - if it is not already a tuple or list\n",
    "                if not isinstance(results, tuple) or isinstance(results, list):\n",
    "                    results = [results]\n",
    "\n",
    "                return results\n",
    "\n",
    "        self.models = [SimpleWrapper(torch.jit.load(model_file))\n",
    "                       for i in range(num_neuron_cores)]\n",
    "\n",
    "        ## Important - please read:\n",
    "        ##     https://github.com/aws/aws-neuron-sdk/blob/master/docs/tensorflow-neuron/tutorial-NeuronCore-Group.md\n",
    "        ## For four cores we use \n",
    "        ##     os.environ['NEURONCORE_GROUP_SIZES'] = \"1,1,1,1\" \n",
    "        ## when launching four threads\n",
    "        ## In this logic exists in worker processes, each process should use \n",
    "        ##     os.environ['NEURONCORE_GROUP_SIZES'] = \"1\"\n",
    "        nc_env = ','.join(['1'] * num_neuron_cores)\n",
    "        os.environ['NEURONCORE_GROUP_SIZES'] = nc_env\n",
    "\n",
    "        self.executor = futures.ThreadPoolExecutor(\n",
    "            max_workers=self.num_neuron_cores)\n",
    "\n",
    "    def eval(self):\n",
    "        for m in self.models:\n",
    "            m.eval()\n",
    "\n",
    "    def train(self):\n",
    "        for m in self.models:\n",
    "            m.train()\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        assert all(isinstance(a, torch.Tensor)\n",
    "                   for a in args), \"Non tensor input - tensors are needed to generate batches\"\n",
    "        assert all(a.shape[0] % self.num_neuron_cores ==\n",
    "                   0 for a in args), \"Batch size must be even multiple of the number of parallel neuron cores\"\n",
    "\n",
    "        args_per_core = [[] for i in range(self.num_neuron_cores)]\n",
    "\n",
    "        # Split args\n",
    "        for a in args:\n",
    "            # Based on batch size for arg\n",
    "            step_size = a.shape[0] // self.num_neuron_cores\n",
    "            for i in range(self.num_neuron_cores):\n",
    "                # Append a slice of a view\n",
    "                start = i * step_size\n",
    "                end = (i + 1) * step_size\n",
    "\n",
    "                # Slice\n",
    "                args_per_core[i].append(a[start:end])\n",
    "\n",
    "        # Call each core with their split and wait to complete\n",
    "        running = {self.executor.submit(\n",
    "            self.models[idx], *args_per_core[idx]): idx for idx in range(self.num_neuron_cores)}\n",
    "\n",
    "        results = [None] * self.num_neuron_cores\n",
    "\n",
    "        for future in futures.as_completed(running):\n",
    "            idx = running[future]\n",
    "\n",
    "            results[idx] = future.result()\n",
    "\n",
    "        # Remove zero dimensional tensors (unsqueeze)\n",
    "        # Iterate results per core\n",
    "        for ic in range(len(results)):\n",
    "            # Iterate result tuples\n",
    "            for ir in range(len(results[ic])):\n",
    "                # Unsqueeze if zero dimensional or does not look batched (i.e. first dim does not match batch)\n",
    "                if len(results[ic][ir].size()) == 0 or results[ic][ir].shape[0] != self.batch_size:\n",
    "                    results[ic][ir] = torch.unsqueeze(\n",
    "                        results[ic][ir], 0)\n",
    "\n",
    "        # Concatenate\n",
    "        output = results[0][0]\n",
    "\n",
    "        for i in range(1, len(results)):\n",
    "            for j in range(len(results[i])):\n",
    "                output = torch.cat([output, results[i][j]], 0)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can update our inference code for four cores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "import torch\n",
    "import torch_neuron\n",
    "import json\n",
    "import numpy as np\n",
    "from urllib import request\n",
    "from torchvision import models, transforms, datasets\n",
    "\n",
    "## Assuming you are working on and inf1.xlarge or inf1.2xlarge\n",
    "num_neuron_cores = 4\n",
    "\n",
    "## Create an image directory containing a small kitten\n",
    "os.makedirs(\"./torch_neuron_test/images\", exist_ok=True)\n",
    "request.urlretrieve(\"https://raw.githubusercontent.com/awslabs/mxnet-model-server/master/docs/images/kitten_small.jpg\",\n",
    "                    \"./torch_neuron_test/images/kitten_small.jpg\")\n",
    "\n",
    "## Fetch labels to output the top classifications\n",
    "request.urlretrieve(\"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\",\"imagenet_class_index.json\")\n",
    "idx2label = []\n",
    "\n",
    "with open(\"imagenet_class_index.json\", \"r\") as read_file:\n",
    "    class_idx = json.load(read_file)\n",
    "    idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]\n",
    "    \n",
    "## Import a sample image and normalize it into a tensor\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "eval_dataset = datasets.ImageFolder(\n",
    "    os.path.dirname(\"./torch_neuron_test/\"),\n",
    "    transforms.Compose([\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "    ])\n",
    ")\n",
    "image, _ = eval_dataset[0]\n",
    "image = torch.tensor(image.numpy()[np.newaxis, ...])\n",
    "\n",
    "## Load model\n",
    "model_neuron = NeuronSimpleDataParallel( 'resnet50_neuron.pt', num_neuron_cores )\n",
    "\n",
    "## Create a \"batch\" image with enough images to go on each of the four cores\n",
    "batch_image = image\n",
    "\n",
    "for i in range(num_neuron_cores - 1):\n",
    "    batch_image = torch.cat( [batch_image, image], 0 )\n",
    "\n",
    "print(batch_image.shape)\n",
    "\n",
    "## Since the first inference also loads the model to the chip let's exclude it \n",
    "## from timing\n",
    "results = model_neuron( batch_image )\n",
    "\n",
    "## Predict\n",
    "loops = 100\n",
    "start = time()\n",
    "for _ in range(loops):\n",
    "    results = model_neuron( batch_image )\n",
    "elapsed_time = time() - start\n",
    "images_sec = loops * batch_image.size(0) / float(elapsed_time)\n",
    "\n",
    "# Get the top 5 results\n",
    "top5_idx = results[0].sort()[1][-5:]\n",
    "\n",
    "# Lookup and print the top 5 labels\n",
    "top5_labels = [idx2label[idx] for idx in top5_idx]\n",
    "\n",
    "# Sample output will look like below:\n",
    "# ['tiger', 'lynx', 'tiger_cat', 'Egyptian_cat', 'tabby']\n",
    "# Batch size: 1, Throughput: 466.0 images / second\n",
    "\n",
    "print(\"Top 5 labels:\\n {}\".format(top5_labels) )\n",
    "print(\"Batch size: 1, Throughput: {} images / second\".format(round(images_sec,0) ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Infer with different batch sizes on multiple Neuron cores\n",
    "\n",
    "Different models will show better and worse throughput with different batch sizes.  In general neuron models will work best with small batch sizes when compared with GPU inference - even though overall a single neuron instance may outperform a GPU instance on a given task.   \n",
    "\n",
    "As a general best practice we recommend starting with a small batch size and working up to find peak throughput.\n",
    "\n",
    "Now that we are using all four cores we can experiment with compiling and running larger batch sizes on each of our four cores. In the following we compile using a batch size of 5 - but you can use any value, or test multiple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import torch_neuron\n",
    "from torchvision import models\n",
    "import logging\n",
    "\n",
    "## Enable logging so we can see any important warnings\n",
    "logger = logging.getLogger('Neuron')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "image = torch.zeros([batch_size, 3, 224, 224], dtype=torch.float32)\n",
    "\n",
    "## Load a pretrained ResNet50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "## Tell the model we are using it for evaluation (not training)\n",
    "model.eval()\n",
    "\n",
    "## Analyze the model - this will show operator support and operator count\n",
    "analyze_results = torch.neuron.analyze_model( model, example_inputs=[image] )\n",
    "\n",
    "print(analyze_results)\n",
    "\n",
    "## Now compile the model\n",
    "## Note: The \"-O2\" setting is default in recent releases, but may be needed for DLAMI\n",
    "##       and older installed environments ex:model_neuron = torch.neuron.trace(model, example_inputs=[image], compiler_args=\"-O2\")\n",
    "model_neuron = torch.neuron.trace(model, example_inputs=[image])\n",
    "\n",
    "\n",
    "# The output of this step will have the percentage of operations compiled, example:\n",
    "#\n",
    "# INFO:Neuron:The neuron partitioner created 1 sub-graphs\n",
    "# INFO:Neuron:Neuron successfully compiled 1 sub-graphs, Total fused subgraphs = 1, Percent of model sub-graphs successfully compiled = 100.0%\n",
    "\n",
    "## Export to saved model\n",
    "model_neuron.save(\"resnet50_neuron_b{}.pt\".format(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we run the inference with batch size of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "import torch\n",
    "import torch_neuron\n",
    "import json\n",
    "import numpy as np\n",
    "from urllib import request\n",
    "from torchvision import models, transforms, datasets\n",
    "\n",
    "## Assuming you are working on and inf1.xlarge or inf1.2xlarge\n",
    "num_neuron_cores = 4\n",
    "batch_size = 5\n",
    "\n",
    "## Create an image directory containing a small kitten\n",
    "os.makedirs(\"./torch_neuron_test/images\", exist_ok=True)\n",
    "request.urlretrieve(\"https://raw.githubusercontent.com/awslabs/mxnet-model-server/master/docs/images/kitten_small.jpg\",\n",
    "                    \"./torch_neuron_test/images/kitten_small.jpg\")\n",
    "\n",
    "## Fetch labels to output the top classifications\n",
    "request.urlretrieve(\"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\",\"imagenet_class_index.json\")\n",
    "idx2label = []\n",
    "\n",
    "with open(\"imagenet_class_index.json\", \"r\") as read_file:\n",
    "    class_idx = json.load(read_file)\n",
    "    idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]\n",
    "    \n",
    "## Import a sample image and normalize it into a tensor\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "eval_dataset = datasets.ImageFolder(\n",
    "    os.path.dirname(\"./torch_neuron_test/\"),\n",
    "    transforms.Compose([\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "    ])\n",
    ")\n",
    "image, _ = eval_dataset[0]\n",
    "image = torch.tensor(image.numpy()[np.newaxis, ...])\n",
    "\n",
    "## Load model\n",
    "model_neuron = NeuronSimpleDataParallel( 'resnet50_neuron_b{}.pt'.format(batch_size), num_neuron_cores, batch_size=batch_size )\n",
    "\n",
    "## Create a \"batch\" image with enough images to go on each of the four cores\n",
    "batch_image = image\n",
    "\n",
    "for i in range((num_neuron_cores * batch_size) - 1):\n",
    "    batch_image = torch.cat( [batch_image, image], 0 )\n",
    "\n",
    "## Since the first inference also loads the model to the chip let's exclude it \n",
    "## from timing\n",
    "results = model_neuron( batch_image )\n",
    "\n",
    "## Predict\n",
    "start = time()\n",
    "loops = 100\n",
    "for _ in range(loops):\n",
    "    results = model_neuron( batch_image )\n",
    "elapsed_time = time() - start\n",
    "images_sec = loops * batch_image.size(0) / elapsed_time\n",
    "\n",
    "# Get the top 5 results\n",
    "top5_idx = results[0].sort()[1][-5:]\n",
    "\n",
    "# Lookup and print the top 5 labels\n",
    "top5_labels = [idx2label[idx] for idx in top5_idx]\n",
    "print(\"Top 5 labels:\\n {}\".format(top5_labels) )\n",
    "print(\"[Batch Size: {}, Throughput:{} images / second]\".format( \n",
    "    batch_size, round(images_sec,0)))\n",
    "\n",
    "# Sample output will look like below:\n",
    "# ['tiger', 'lynx', 'tiger_cat', 'Egyptian_cat', 'tabby']\n",
    "# Batch Size: 5, Throughput: 626.0 images / second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can experiment with different batch size values to see what gives the best overall throughput"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_aws_neuron_pytorch_p36)",
   "language": "python",
   "name": "conda_aws_neuron_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
