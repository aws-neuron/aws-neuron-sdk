"""
Copyright (C) 2024, Amazon.com. All Rights Reserved

RMSNorm NKI kernel implementation.

"""

import numpy as np
import math
import neuronxcc.nki as nki
import neuronxcc.nki.language as nl


def nki_rmsnorm_kernel(a_tensor, g_tensor, out_tensor):
  # Calculate out_tensor = a_tensor/RMS(a_tensor) * g_tensor
  # Where RMS(a_tensor) = sqrt((1/N) * sum(a_tensor * a_tensor))
  # and N = a_tensor.shape[1]
  # Reduction (mean) is performed in the free (2nd) dimension

  # Make sure shapes match
  assert a_tensor.shape[1] == g_tensor.shape[0]
  assert a_tensor.shape == out_tensor.shape

  # Generate tensor indices to index input tensor
  ix = nl.arange(128)[:, None]
  iw = nl.arange(1)[:, None]
  iy = nl.arange(a_tensor.shape[1])[None, :]

  num_rows = a_tensor.shape[0]

  # Load RMSNorm weight once, reused by rows/tiles of a_tensor
  g_tile = nl.load(g_tensor.reshape((1, g_tensor.shape[0]))[iw, iy])

  # Process 128 rows at a time due to 128-partition tile size limitation
  # Since we're not reducing across the first dimension
  # Tiles can be processed independently
  for i in nl.affine_range(math.ceil(a_tensor.shape[0]/128)):

    # Load input data from external memory to on-chip memory
    a_tile = nl.load(a_tensor[i * 128 + ix, iy],
                    mask=(i * 128 + ix < num_rows))

    # Compute element-wise square of a_tensor
    in_square = nl.square(a_tile)

    # Calculate sum of squared elements, along last dimension
    square_sum = nl.sum(in_square, axis=[1])

    # Scale and get a reciprocal
    mean = square_sum / a_tensor.shape[1]

    # Take square root of mean and then reciprocal with
    # rsqrt API (one ISA instruction)
    rms_reciprocal = nl.rsqrt(mean)

    # Scale the input tensor
    out_tile = nl.multiply(a_tile, rms_reciprocal)

    # Broadcast weight along first axis to match tensor shape
    # num_rows_active = min(num_rows - i * 128, 128)
    g_bcast = g_tile.broadcast_to((128, g_tensor.shape[0]))

    # Multiply with the RMSNorm weight
    out_tile[...] = nl.multiply(out_tile, g_bcast,
                           mask=(i * 128 + ix < num_rows))

    # store the addition results back to external memory (out_tensor)
    nl.store(out_tensor[i * 128 + ix, iy], value=out_tile,
            mask=(i * 128 + ix < num_rows))


if __name__ == "__main__":
  a = np.random.rand(128, 512).astype(np.float32)
  g = np.random.rand(512).astype(np.float32)
  output_nki  = np.zeros(a.shape, dtype=a.dtype)

  nki_rmsnorm_kernel_baremetal = nki.baremetal(nki_rmsnorm_kernel)
  nki_rmsnorm_kernel_baremetal(a, g, output_nki)
  print(f"output_nki={output_nki}")

  # One-line numpy RMSNorm
  output_np = a*(1.0/np.sqrt(np.mean(a*a, axis=1).reshape(a.shape[0],1)))*g
  print(f"output_np={output_np}")

  allclose = np.allclose(output_np, output_nki, atol=1e-4, rtol=1e-2)
  if allclose:
    print("NKI and NumPy match")

  assert allclose