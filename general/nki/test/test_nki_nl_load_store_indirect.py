"""
Copyright (C) 2024, Amazon.com. All Rights Reserved

"""
import unittest

import numpy as np
import neuronxcc.nki as nki
import neuronxcc.nki.isa as nisa
import neuronxcc.nki.language as nl
...

nki_jit = nki.trace
simulate_kernel = nki.simulate_kernel

########################################################################
# NOTE: if you modify this file, make sure to update the source .py with
# NOTE: the correct line numbers under .. literalinclude:: directive
########################################################################

@nki_jit
def example_indirect_load_1(data_tensor, idx_tensor, out_tensor):
  ############################################################################################
  # Indirect DMA read example 1:
  # - data_tensor on HBM has shape [128 x 512].
  # - idx_tensor on HBM has shape [64] (with values [0, 2, 4, 6, ...]).
  # - idx_tensor values read from HBM and stored in SBUF idx_tile of shape [64 x 1]
  # - data_tensor values read from HBM indexed by values in idx_tile 
  #   and store into SBUF data_tile of shape [64 x 512].
  ############################################################################################
  i_p = nl.arange(64)[:, None]
  i_f = nl.arange(512)[None, :]

  idx_tile = nl.load(idx_tensor[i_p]) # indices have to be in SBUF
  data_tile = nl.load(data_tensor[idx_tile[i_p, 0], i_f]) 
  ...

  nl.store(out_tensor, value=data_tile)

@nki_jit
def example_indirect_load_2(data_tensor, out_tensor):
  n, m = data_tensor.shape
  assert n == 128 and m == 512
  ############################################################################################
  # Indirect DMA read example 2:
  # - data_tensor on HBM has shape [128 x 512].
  # - idx_tile on SBUF has shape [64 x 1] (with values [[0], [2], [4], ...] generated by iota)
  # - data_tensor values read from HBM indexed by values in idx_tile 
  #   and store into SBUF data_tile of shape [64 x 512].
  ############################################################################################
  i_f = nl.arange(512)[None, :]
  
  idx_expr = 2*nl.arange(64)[:, None]
  idx_tile = nisa.iota(idx_expr, dtype=np.int32)
  data_tile = nl.load(data_tensor[idx_tile, i_f]) 
  ...

  nl.store(out_tensor, value=data_tile)

@nki_jit
def example_indirect_save_1(in_tensor, idx_tensor, data_tensor):
  data_tile = nl.load(in_tensor)
  ...
  ##################################################################################
  # Indirect DMA write example 1:
  #  - data_tensor has shape [128 x 512].
  #  - idx_tensor on HBM has shape [64] (with values [0, 2, 4, 6, ...]).
  #  - idx_tensor values read from HBM and stored in SBUF idx_tile.
  #  - data_tile of shape [64 x 512] values written into
  #    HBM data_tensor indexed by values in idx_tile.
  ##################################################################################
  i_p = nl.arange(64)[:, None]
  i_f = nl.arange(512)[None, :]
  idx_tile = nl.load(idx_tensor[i_p]) # indices have to be in SB

  nl.store(data_tensor[idx_tile[i_p, 0], i_f], value=data_tile[0:64, 0:512])


@nki_jit
def example_indirect_save_2(in_tensor, data_tensor):
  n, m = in_tensor.shape
  i_f = nl.arange(m)[None, :]
  data_tile = nl.load(in_tensor)
  assert n == 64 and m == 512
  ...
  #############################################################################################
  # Indirect DMA write example 2:
  #  - data_tensor has shape [128 x 512].
  #  - idx_tile on SBUF has shape [64 x 1] (with values [[0], [2], [4], ...] generated by iota)
  #  - data_tile of shape [64 x 512] values written into
  #    HBM data_tensor indexed by values in idx_tile.
  #############################################################################################
  idx_expr = 2*nl.arange(64)[:, None]
  idx_tile = nisa.iota(idx_expr, dtype=np.int32)
  
  nl.store(data_tensor[idx_tile, i_f], value=data_tile[0:64, 0:512]) 


class TestNkiExampleNlLoadStoreIndirect(unittest.TestCase):
  def test_indirect_load_1(self):
    in_tensor = np.random.random_sample([128, 512]).astype(np.float32)
    out_tensor = np.random.random_sample([64, 512]).astype(np.float32)
    idx_tensor = 2*np.arange(64, dtype=np.int32)
    golden = in_tensor[idx_tensor]

    nki.simulate_kernel(example_indirect_load_1, in_tensor, idx_tensor, out_tensor)
    self.assertTrue(np.allclose(out_tensor, golden))

  def test_indirect_load_2(self):
    in_tensor = np.random.random_sample([128, 512]).astype(np.float32)
    out_tensor = np.random.random_sample([64, 512]).astype(np.float32)
    idx_tensor = 2*np.arange(64, dtype=np.int32)
    golden = in_tensor[idx_tensor]

    nki.simulate_kernel(example_indirect_load_2, in_tensor, out_tensor)
    self.assertTrue(np.allclose(out_tensor, golden))

  def test_indirect_save_1(self):
    in_tensor = np.random.random_sample([64, 512]).astype(np.float32)
    out_tensor = np.random.random_sample([128, 512]).astype(np.float32)
    idx_tensor = 2*np.arange(64, dtype=np.int32)

    nki.simulate_kernel(example_indirect_save_1, in_tensor, idx_tensor, out_tensor)
    self.assertTrue(np.allclose(out_tensor[idx_tensor], in_tensor))

  def test_indirect_save_2(self):
    in_tensor = np.random.random_sample([64, 512]).astype(np.float32)
    out_tensor = np.random.random_sample([128, 512]).astype(np.float32)
    idx_tensor = 2*np.arange(64, dtype=np.int32)

    nki.simulate_kernel(example_indirect_save_2, in_tensor, out_tensor)
    self.assertTrue(np.allclose(out_tensor[idx_tensor], in_tensor))
   
