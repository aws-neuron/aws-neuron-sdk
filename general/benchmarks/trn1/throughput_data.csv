Model,Scripts,Framework,Inst. Type,Throughput (/sec),Latency P50 (ms),Latency P99 (ms),Application Type,Neuron Version,Run Mode,Batch Size,Sequence Length,Model Data Type,Compilation Autocast Data Type
albert-base-v2,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.0,trn1.2xlarge,2665.95,11.99,12.26,Batch,2.9.0,Data Parallel,16,128,FP32,Matmult-BF16
bert-base-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.0,trn1.2xlarge,2616.35,6.1,6.23,Batch,2.9.0,Data Parallel,8,128,FP32,Matmult-BF16
bert-base-cased-finetuned-mrpc,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.0,trn1.2xlarge,3012.41,5.3,5.33,Batch,2.9.0,Data Parallel,8,128,FP32,Matmult-BF16
bert-large-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.0,trn1.2xlarge,931.36,8.57,8.69,Batch,2.9.0,Data Parallel,4,128,FP32,Matmult-BF16
distilbert-base-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.0,trn1.2xlarge,4198.35,7.43,10.58,Batch,2.9.0,Data Parallel,16,128,FP32,Matmult-BF16
roberta-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.0,trn1.2xlarge,2564.26,6.22,6.64,Batch,2.9.0,Data Parallel,8,128,FP32,Matmult-BF16
roberta-large,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.0,trn1.2xlarge,919.37,8.68,8.81,Batch,2.9.0,Data Parallel,4,128,FP32,Matmult-BF16