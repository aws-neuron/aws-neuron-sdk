Model,Scripts,Framework,Inst. Type,Task,Throughput (tokens/second),Latency per Token P50 (ms),Latency per Token P99 (ms),Application Type,Neuron Version,Run Mode,TP Degree,DP Degree,Batch Size,Sequence Length,Input Length,Output Length,Model Data Type,Compilation Autocast Data Type
Llama-2-13b,:llama-sample:`Sample <meta-llama-2-13b-sampling>`,Transformers NeuronX,Inf2.48xlarge,Text Generation,227.8,4.39,4.4,Real Time,2.17.0,Tensor Parallel,24,1,1,2048,1024,1024,FP16,Matmult-BF16
Llama-2-13b,:llama-sample:`Sample <meta-llama-2-13b-sampling>`,Transformers NeuronX,Inf2.48xlarge,Text Generation,115.5,8.66,8.69,Real Time,2.17.0,Tensor Parallel,24,1,1,4096,128,3968,FP16,Matmult-BF16
Llama-2-13b,:llama-sample:`Sample <meta-llama-2-13b-sampling>`,Transformers NeuronX,Inf2.48xlarge,Text Generation,2589.6,0.38,0.39,Real Time,2.17.0,Tensor Parallel,24,1,1,4096,3968,128,FP16,Matmult-BF16
