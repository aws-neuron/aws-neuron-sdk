Model,Scripts,Framework,Inst. Type,Throughput (/sec),Latency P50 (ms),Latency P99 (ms),Application Type,Neuron Version,Run Mode,Batch Size,Sequence Length,Model Data Type,Compilation Autocast Data Type
albert-base-v2,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.0,Inf2.xlarge,2437.5,3.15,5.25,Batch,2.9.0,Data Parallel,4,128,FP32,Matmult-BF16
bert-base-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.0,Inf2.xlarge,2599.3,6.13,6.45,Batch,2.9.0,Data Parallel,8,128,FP32,Matmult-BF16
bert-base-cased-finetuned-mrpc,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.0,Inf2.xlarge,2977.7,5.33,5.7,Batch,2.9.0,Data Parallel,8,128,FP32,Matmult-BF16
bert-large-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.0,Inf2.xlarge,866.2,18.13,21.47,Batch,2.9.0,Data Parallel,8,128,FP32,Matmult-BF16
distilbert-base-cased,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.0,Inf2.xlarge,3721.4,8.96,11.61,Batch,2.9.0,Data Parallel,4,128,FP32,Matmult-BF16
roberta-base,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.0,Inf2.xlarge,2379.1,3.26,4.43,Batch,2.9.0,Data Parallel,4,128,FP32,Matmult-BF16
roberta-large,:benchmark-pt:`Benchmark <inf2>`,PyTorch 1.13.0,Inf2.xlarge,885.6,8.86,10.61,Batch,2.9.0,Data Parallel,4,128,FP32,Matmult-BF16
opt-13b,:benchmark-pt:`Benchmark <opt>`,PyTorch 1.13.0,Inf2.48xlarge,1354.9,141.6,151.9,Batch,2.9.0,Tensor Parallel,256,2048,FP16,Matmult-BF16
opt-30b,:benchmark-pt:`Benchmark <opt>`,PyTorch 1.13.0,Inf2.48xlarge,626.9,82.6,106.9,Batch,2.9.0,Tensor Parallel,256,2048,FP16,Matmult-BF16
opt-66b,:benchmark-pt:`Benchmark <opt>`,PyTorch 1.13.0,Inf2.48xlarge,733.4,248.6,257.8,Batch,2.9.0,Tensor Parallel,64,2048,FP16,Matmult-BF16
