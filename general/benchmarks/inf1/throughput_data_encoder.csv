Model,Scripts,Source,Framework,Inst. Type,Num Cores,Seq. Length,Avg Throughput (/sec),Max Throughput,Threads,Latency P50 (ms),Latency P90 (ms),Latency P95 (ms),Latency P99 (ms),Application Type,Neuron Version,Run Mode,Batch Size,N Models,Workers per Model,Model details
BERT base (bert-base-cased),:compile-pt:`Compile <bert-base-cased>` + :benchmark-pt:`Benchmark <bert-base-cased>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1095.4,,8,58.3,,,65.0,Batch,2.20.0,Data Parallel,8,4,2,"fp32, sequence-length=128"
BERT base (bert-base-uncased),:compile-pt:`Compile <bert-base-uncased>` + :benchmark-pt:`Benchmark <bert-base-uncased>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1180.7,,8,40.6,,,45.0,Batch,2.20.0,Data Parallel,6,4,2,"fp32, sequence-length=128"
DistilBERT base (distilbert-base-uncased-finetuned-sst-2-english),:compile-pt:`Compile <distilbert-base-uncased-finetuned-sst-2-english>` + :benchmark-pt:`Benchmark <distilbert-base-uncased-finetuned-sst-2-english>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1875.3,,8,33.7,,,54.1,Batch,2.20.0,Data Parallel,8,4,2,"fp32, sequence-length=128"
DistilBERT base (distilbert-base-uncased),:compile-pt:`Compile <distilbert-base-uncased>` + :benchmark-pt:`Benchmark <distilbert-base-uncased>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1876.7,,8,33.7,,,53.2,Batch,2.20.0,Data Parallel,8,4,2,"fp32, sequence-length=128"
DistilRoBERTa base (distilroberta-base),:compile-pt:`Compile <distilroberta-base>` + :benchmark-pt:`Benchmark <distilroberta-base>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1512.9,,8,15.0,,,25.9,Batch,2.20.0,Data Parallel,6,4,1,"fp32, sequence-length=128"
BERT base,:ref:`HuggingFace Pretrained BERT </src/examples/pytorch/bert_tutorial/tutorial_pretrained_bert.ipynb>`,,PyTorch 1.13,inf1.xlarge,,,1056,,,20,,,21,Batch,2.20.0,Data Parallel,4,,,"fp32, bert-base-cased-finetuned-mrpc, sequence-length=128"
BERT base,:ref:`Using NeuronCore Pipeline </src/examples/pytorch/pipeline_tutorial/neuroncore_pipeline_pytorch.ipynb>`,,PyTorch 1.13,inf1.6xlarge,,,2009.1,,,5.9,,,6.3,Real Time,2.20.0,Model Pipeline,1,,,"fp32, bert-base-uncased, sequence-length=128"
BERT base,:ref:`HuggingFace distilBERT with Tensorflow2 </src/examples/tensorflow/huggingface_bert/huggingface_bert.ipynb>`,,Tensorflow 2.10,inf1.6xlarge,,,2123.4,,,30.0,,,32.2,Batch,2.20.0,Data Parallel,16,,,"fp32, distilbert-base-uncased-finetuned-sst-2-english, sequence-length=128"
