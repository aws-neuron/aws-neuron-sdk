Model,Scripts,Source,Framework,Inst. Type,Num Cores,Seq. Length,Avg Throughput (/sec),Max Throughput,Threads,Latency P50 (ms),Latency P90 (ms),Latency P95 (ms),Latency P99 (ms),Application Type,Neuron Version,Run Mode,Batch Size,N Models,Workers per Model,Model details
BERT base (bert-base-cased),:compile-pt:`Compile <bert-base-cased>` + :benchmark-pt:`Benchmark <bert-base-cased>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1121,,8,57.0,,,60.6,Batch,2.18.0,Data Parallel,8,4,2,"fp32, sequence-length=128"
BERT base (bert-base-uncased),:compile-pt:`Compile <bert-base-uncased>` + :benchmark-pt:`Benchmark <bert-base-uncased>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1181.5,,8,40.6,,,45.2,Batch,2.18.0,Data Parallel,6,4,2,"fp32, sequence-length=128"
DistilBERT base (distilbert-base-uncased-finetuned-sst-2-english),:compile-pt:`Compile <distilbert-base-uncased-finetuned-sst-2-english>` + :benchmark-pt:`Benchmark <distilbert-base-uncased-finetuned-sst-2-english>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1871.5,,8,33.7,,,54.6,Batch,2.18.0,Data Parallel,8,4,2,"fp32, sequence-length=128"
DistilBERT base (distilbert-base-uncased),:compile-pt:`Compile <distilbert-base-uncased>` + :benchmark-pt:`Benchmark <distilbert-base-uncased>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1875.3,,8,33.7,,,53.4,Batch,2.18.0,Data Parallel,8,4,2,"fp32, sequence-length=128"
DistilRoBERTa base (distilroberta-base),:compile-pt:`Compile <distilroberta-base>` + :benchmark-pt:`Benchmark <distilroberta-base>`,HuggingFace,PyTorch 1.13.1,inf1.xlarge,4,128,1498.4,,8,15.1,,,26.8,Batch,2.18.0,Data Parallel,6,4,1,"fp32, sequence-length=128"
BERT base,:ref:`HuggingFace Pretrained BERT </src/examples/pytorch/bert_tutorial/tutorial_pretrained_bert.ipynb>`,,PyTorch 1.13,inf1.xlarge,,,1056,,,21,,,21,Batch,2.18.0,Data Parallel,4,,,"fp32, bert-base-cased-finetuned-mrpc, sequence-length=128"
BERT base,:ref:`Using NeuronCore Pipeline </src/examples/pytorch/pipeline_tutorial/neuroncore_pipeline_pytorch.ipynb>`,,PyTorch 1.13,inf1.6xlarge,,,1968.3,,,6.0,,,6.4,Real Time,2.18.0,Model Pipeline,1,,,"fp32, bert-base-uncased, sequence-length=128"
BERT base,:ref:`HuggingFace distilBERT with Tensorflow2 </src/examples/tensorflow/huggingface_bert/huggingface_bert.ipynb>`,,Tensorflow 2.10,inf1.6xlarge,,,2124.7,,,30.0,,,32.5,Batch,2.18.0,Data Parallel,16,,,"fp32, distilbert-base-uncased-finetuned-sst-2-english, sequence-length=128"
