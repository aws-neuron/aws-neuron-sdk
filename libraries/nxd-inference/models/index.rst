.. _nxdi-models-index:

Get started with Inference
==============================================

.. meta::
  :description: Reference guide for running inference with NeuronX Distributed Inference (NxDI) on AWS Neuron for Trainium and Inferentia ML chips.

This guide provides instructions on how to run inference on Neuron devices with **NeuronX Distributed Inference (NxDI)** and how to determine appropriate configurations for both online and offline use cases.

.. _nxdi-models-llama3-index:

Llama 3
---------------------------

Meta's Llama 3 family includes large language models available in multiple sizes and versions. Select the model variant that matches your application requirements:

.. grid:: 1
  :gutter: 1

  .. grid-item-card:: Llama 3.3 70B

    Meta's multilingual LLM, featuring 70B parameters and Grouped Query Attention.

    :bdg-ref-primary:`Quickstart <nxdi-models-llama-3-3-70b-instruct-quickstart>`

.. note::
  Instructions for additional models will be available soon. For a complete list of supported model architectures, refer to this :ref:`developer guide <nxdi-model-reference>`.
