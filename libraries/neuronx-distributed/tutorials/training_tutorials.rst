.. _nxd_training_tutorials:

Training Tutorials
============================================================

.. toctree::
    :maxdepth: 1
    :hidden:
        
    Training using Tensor Parallelism </libraries/neuronx-distributed/tutorials/training>
    Training GPT-NeoX 6.9B using TP and ZeRO-1 </libraries/neuronx-distributed/tutorials/training-gpt-neox>
    Training GPT-NeoX 20B using TP and ZeRO-1 </libraries/neuronx-distributed/tutorials/training-gpt-neox-20b>
    Training Llama 3.1 8B/Llama 3 8B/Llama 2 7B using TP and ZeRO-1 </libraries/neuronx-distributed/tutorials/training_llama_tp_zero1>
    Training Llama 3.1 70B/Llama 3 70B/Llama 2 13B/70B using TP and PP </libraries/neuronx-distributed/tutorials/training_llama_tp_pp>
    Training Llama-2-7B/13B/70B using TP and PP with PyTorch-Lightning </libraries/neuronx-distributed/tutorials/training_llama2_tp_pp_ptl>
    Fine-tuning Llama3 8B with tensor parallelism and LoRA using Neuron PyTorch-Lightning </libraries/neuronx-distributed/tutorials/finetune_llama3_8B_ptl_lora>

.. include:: /libraries/neuronx-distributed/tutorials/nxd_training_tutorials.txt

